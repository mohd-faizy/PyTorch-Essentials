{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7CxbK15nlg9"
      },
      "source": [
        "# **Custom Datasets**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dkpcDsrhbQw"
      },
      "source": [
        "### **1. Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqucpx6EhdF4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9DyK9_NhoI-"
      },
      "source": [
        "Setup device-agnostic code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBF-uykYhla4"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zP8JT6AiAsG"
      },
      "source": [
        "### **2. Get Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3YIQEb_cBIqZ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Step 1: Set up the path\n",
        "url = \"https://github.com/mohd-faizy/PyTorch-Essentials/raw/main/_datasets/pizza_steak_sushi.zip\"\n",
        "image_path = Path(\"data/pizza_steak_sushi\")\n",
        "image_path.mkdir(parents=True, exist_ok=True)\n",
        "zip_path = image_path.parent / \"pizza_steak_sushi.zip\"\n",
        "\n",
        "# Step 2: Download the zip file containing the data\n",
        "zip_path.write_bytes(requests.get(url).content)\n",
        "\n",
        "# Step 3: Unzip the downloaded file into the image directory\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UucURN4XQPm"
      },
      "source": [
        "### **3.Data Preparation and Data Exploration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5q8-JQ5Oa1Xl"
      },
      "outputs": [],
      "source": [
        "image_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-e5oW2kXen2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "walk_through_dir(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsQyNkE4X-Pj"
      },
      "outputs": [],
      "source": [
        "# Setup train and test paths\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fMZl6NiX9CU"
      },
      "source": [
        "### **4. Visualizing the Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjH_H6nVjmkT"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from PIL import Image # Python Imaging Library\n",
        "\n",
        "## set seed\n",
        "# random.seed(42)\n",
        "\n",
        "# 1. get all images path\n",
        "# Use glob to find all .jpg images in subdirectories (two levels deep)\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "# 2. pick a random image path\n",
        "# Randomly select one image path from the list of all image paths\n",
        "random_image_path = random.choice(image_path_list)\n",
        "\n",
        "# 3. Get image class from the path name\n",
        "# The image class in the name of the directory where the image is stored\n",
        "image_class = random_image_path.parent.stem\n",
        "\n",
        "# 4. Open image\n",
        "# Open the image using Pillow's Image class\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "# 5. print metadata\n",
        "print(f\"Random Image path: {random_image_path}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"height x width: {img.height} x {img.width}\")\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4ob7DO0sXno"
      },
      "source": [
        "### **5. `Image To Array`** **HWC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5cPlZpqllph"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Turn the image to array\n",
        "img_array = np.array(img)\n",
        "\n",
        "# plot image with matplotlib\n",
        "plt.figure(figsize=(5, 3))\n",
        "plt.imshow(img_array);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQZoIjMzsqaH"
      },
      "outputs": [],
      "source": [
        "print(f\"{img_array.shape} -> height, width, color channels\")\n",
        "print(f\"{img_array.ndim}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzoOBIX8tUpm"
      },
      "outputs": [],
      "source": [
        "img_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fhls-fBmua1u"
      },
      "source": [
        "### **6. Transforming data** (`Image To Tensor`) **CHW**\n",
        "\n",
        "- Numerical representation of our images\n",
        "\n",
        "- Turn it into a `torch.utils.data.Dataset` and subsequently a `torch.utils.data.DataLoader`, we'll call these `Dataset` and `DataLoader`.\n",
        "\n",
        "- Transforms help you get your images ready to be used with a model/perform data augmentation - [**PyTorch Transform**](https://pytorch.org/vision/stable/transforms.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_cJ-T6gt2A2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYC8bI3ondfM"
      },
      "source": [
        "```python\n",
        "from torchvision.transforms import ToTensor\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIF5Om1Lmx9y"
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose([         # Write a transform for image\n",
        "    transforms.Resize(size=(64, 64)),         # Resize our images to 64x64\n",
        "    transforms.RandomHorizontalFlip(p=0.5),   # Flip the images randomly on the horizontal ~ prob 50% i.e img transfrom 50% of time\n",
        "    transforms.ToTensor()                     # Turn the image into a torch.Tensor\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUUaijcennxY"
      },
      "outputs": [],
      "source": [
        "data_transform(img).shape, data_transform(img).dtype # CHW"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emwp2FX2-DXx"
      },
      "source": [
        "**Note:** `PyTorch` transform our image to color channel first `[3, 64, 64]`, while `Matplotlib` prefer color channel last `[64, 64, 3]`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kPOLOaYn1Um"
      },
      "outputs": [],
      "source": [
        "def plot_transformed_images(image_path:list, transform, n=3, seed=None):\n",
        "    \"\"\"\n",
        "    This function takes a list of image paths, applies the specified transformation,\n",
        "    and plots the original and transformed versions side by side. The seed parameter\n",
        "    allows for reproducible random sampling. You can use this function by passing\n",
        "    your own image_path_list and data_transform.\n",
        "\n",
        "    Args:\n",
        "        `image_paths` (list): A list of image file paths.\n",
        "        `transform`: An image transformation function (e.g., rotation, scaling, etc.).\n",
        "        `n` (int, optional): The number of images to select (default is 3).\n",
        "        `seed` (int, optional): Random seed for reproducibility (default is None).\n",
        "\n",
        "    Returns:\n",
        "        None (plots the images)\n",
        "\n",
        "    Example usage:\n",
        "        plot_transformed_images(image_paths=image_path_list,\n",
        "                                transform=data_transform,\n",
        "                                n=3,\n",
        "                                seed=None)\n",
        "    \"\"\"\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "    random_image_paths = random.sample(image_path, k=n)\n",
        "\n",
        "    for image_path in random_image_paths:\n",
        "        with Image.open(image_path) as f:\n",
        "            fig, ax = plt.subplots(nrows=1, ncols=2)\n",
        "            # Original Image\n",
        "            ax[0].imshow(f)\n",
        "            ax[0].set_title(f\"Original\\nSize: {f.size}\")\n",
        "            ax[0].axis(False)\n",
        "\n",
        "            # Transform and plot image\n",
        "            # Note: permute() will change shape of image to suit matplotlib\n",
        "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
        "            transformed_image = transform(f).permute(1, 2, 0)\n",
        "            ax[1].imshow(transformed_image)\n",
        "            ax[1].set_title(f\"Transformed\\nShape: {transformed_image.shape}\")\n",
        "            ax[1].axis(False)\n",
        "\n",
        "            fig.suptitle(f\"class: {image_path.parent.stem}\", fontsize=18, weight='bold')\n",
        "\n",
        "\n",
        "plot_transformed_images(image_path=image_path_list,\n",
        "                        transform=data_transform,\n",
        "                        n=3,\n",
        "                        seed=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shRGaPdRyXpQ"
      },
      "source": [
        "### **7. Loading Dataset ~ `Option-1`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uVIy_B55flU"
      },
      "source": [
        "#### Loading Image Data using **Pytorch** `ImageFolder`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kWY1c2lxSme"
      },
      "source": [
        "**Note:** The `ImageFolder` class in PyTorch expects the images to be arranged in a specific folder structure by default. Here’s how it should be organized:\n",
        "\n",
        "\n",
        "```\n",
        "my_dataset/\n",
        "    ├──train/\n",
        "    │   ├── cats/\n",
        "    │   │   ├── cat1.jpg\n",
        "    │   │   ├── cat2.jpg\n",
        "    │   │   └── ...\n",
        "    │   ├── dogs/\n",
        "    │   │   ├── dog1.jpg\n",
        "    │   │   ├── dog2.jpg\n",
        "    │   │   └── ...\n",
        "    │   └── birds/\n",
        "    │        ├── bird1.jpg\n",
        "    │        ├── bird2.jpg\n",
        "    │        └── ...\n",
        "    └──test/    \n",
        "        ├── cats/\n",
        "        │   ├── cat1.jpg\n",
        "        │   ├── cat2.jpg\n",
        "        │   └── ...\n",
        "        ├── dogs/\n",
        "        │   ├── dog1.jpg\n",
        "        │   ├── dog2.jpg\n",
        "        │   └── ...\n",
        "        └── birds/\n",
        "            ├── bird1.jpg\n",
        "            ├── bird2.jpg\n",
        "            └── ...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mkf4a_jzeAV"
      },
      "source": [
        "#### 7.1 `ImageFolder`\n",
        "\n",
        "```python\n",
        "from torchvision.datasets import ImageFolder\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIjfSB52GGvz"
      },
      "outputs": [],
      "source": [
        "train_dir, test_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GRZZnqpzwcF"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "train_data = ImageFolder(root=train_dir,\n",
        "                         transform=data_transform,\n",
        "                         target_transform=None)\n",
        "\n",
        "test_data = ImageFolder(root=test_dir,\n",
        "                        transform=data_transform,\n",
        "                        target_transform=None)\n",
        "\n",
        "train_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU92d6cWP_T_"
      },
      "outputs": [],
      "source": [
        "len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUBz4dNNGOLY"
      },
      "outputs": [],
      "source": [
        "class_names = train_data.classes\n",
        "class_dict = train_data.class_to_idx\n",
        "\n",
        "print(class_names)\n",
        "print(class_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1w1rn6zQIYI"
      },
      "outputs": [],
      "source": [
        "print(train_data.samples[0])      # image, label\n",
        "print(train_data.samples[0][0])   # image\n",
        "print(train_data.samples[0][1])   # Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DECNN1feQo9w"
      },
      "outputs": [],
      "source": [
        "Image.open(train_data.samples[0][0]) # sample image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzWBPBLYRPLh"
      },
      "outputs": [],
      "source": [
        "# Index on the train_data Dataset to get a single image and label\n",
        "img, label = train_data[0][0], train_data[0][1]\n",
        "print(f\"Image Tensor: {img}\")\n",
        "print(f\"Image Shape: {img.shape}\")\n",
        "print(f\"Image datatype: {img.dtype}\")\n",
        "print(f\"image label: {label}\")\n",
        "print(f\"label datatype: {type(label)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LG_Laee4TMUa"
      },
      "outputs": [],
      "source": [
        "# Plot: Matplotlib ~ HWC -> color channel last\n",
        "# Rearrange the order dimensions\n",
        "img_permute = img.permute(1, 2, 0)\n",
        "\n",
        "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
        "print(f\"Image Permute: {img_permute.shape} -> [height, width, color_channels]\")\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.imshow(img_permute)\n",
        "plt.axis(\"off\")\n",
        "plt.title(class_names[label], fontsize=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbVMENtEzmX2"
      },
      "source": [
        "#### 7.2 `DataLoader`\n",
        "\n",
        "```python\n",
        "from torch.utils.data import DataLoader\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poVlbwXR_pBx"
      },
      "source": [
        "A `DataLoader` help us turn our `Dataset`'s into iterables and we can customise the `batch_size` so our model can see `batch_size` images at a time.\n",
        "\n",
        "1. **Data Preparation**: The DataLoader helps you standardize these processes, making your code more readable and maintainable.\n",
        "\n",
        "2. **Batching**: It allows you to define how many training or testing samples to use in a single iteration. Working with batches of data makes training and testing more manageable.\n",
        "\n",
        "3. **Shuffling**: DataLoader can shuffle data for you as it loads batches. This increases dataset representativeness and prevents accidental `skewness`.\n",
        "\n",
        "4. **Multi-processing**: PyTorch optimizes running multiple processes at once, utilizing modern `CPUs` and `GPUs`. DataLoader lets you define how many workers should go at once.\n",
        "\n",
        "5. **Merging Datasets**: Optionally, you can merge multiple datasets together using DataLoader.\n",
        "\n",
        "6. **Direct Loading on CUDA**: If you’re using a GPU, DataLoader can load data directly onto CUDA tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLTcpdatAvSk"
      },
      "outputs": [],
      "source": [
        "# Checking the number of avalible core\n",
        "import os\n",
        "os.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6DgzXWLzBXY"
      },
      "outputs": [],
      "source": [
        "# Turn the train test datasets into DataLoaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "\n",
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=BATCH_SIZE,\n",
        "                              num_workers=2, # available cores for parallel data loading\n",
        "                              shuffle=False)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             num_workers=2,\n",
        "                             shuffle=False)\n",
        "\n",
        "train_dataloader, test_dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiJkheFHzBR-"
      },
      "outputs": [],
      "source": [
        "len(train_dataloader), len(test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bydhta7c6Qwl"
      },
      "outputs": [],
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "\n",
        "# Batch size will now be 1, we can change the batch size\n",
        "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
        "print(f\"Label shape: {label.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eVOQ2j4zBOu"
      },
      "source": [
        "### **8. Loading Dataset ~ `Option-2`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25-mySt_5UIr"
      },
      "source": [
        "**Loading Image Data with a `Custom` Dataset Function**\n",
        "\n",
        "- **Desired functionality for custom function:**\n",
        "    - load images from file.\n",
        "    - get `class names` from the Dataset.\n",
        "    - get `classes as dictionary` from the Dataset.\n",
        "\n",
        "- **Pros**\n",
        "    - Can create the `dataset` out of almost anything.\n",
        "    - For complex datasets, custom classes can allow for optimizations like caching or lazy loading mechanisms, which might not be feasible with simpler approaches.\n",
        "\n",
        "- **Cons**\n",
        "    - Custom code can be prone to errors.\n",
        "    - Maintenance Overhead: As your dataset or data loading requirements change, you might need to modify the custom class to accommodate those changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2wM_VtKxSmn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from typing import Tuple, Dict, List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSBN-E6wxSmn"
      },
      "outputs": [],
      "source": [
        "# Instance of torchvision.datasets.ImageFolder()\n",
        "train_data.classes, train_data.class_to_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNhCW6syxSmn"
      },
      "source": [
        "#### **8.1 Creating a helper function to get class names**\n",
        "\n",
        "- Uses `os.scandir()` to traverse a target directory (ideally in standard image classification format).\n",
        "- Extracts `class` names from the directory structure.\n",
        "- Raises an `error` if no class names are found (indicating potential directory structure issues).\n",
        "- Creates a dictionary and a list containing the class names.\n",
        "- Returns the dictionary and list of class names."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYOvp4CwxSmo"
      },
      "source": [
        "---\n",
        "\n",
        "```python\n",
        "target_dir = train_dir\n",
        "print(f\"Target directory: {target_dir}\")\n",
        "\n",
        "# Step 1: Scan the target directory\n",
        "entries = os.scandir(target_dir)\n",
        "\n",
        "# Step 2: Iterate through the entries and print their details\n",
        "for entry in entries:\n",
        "    print(f\"Name: {entry.name}, Path: {entry.path}, Is File: {entry.is_file()}, Is Dir: {entry.is_dir()}\")\n",
        "```\n",
        "\n",
        "```\n",
        "Target directory: data\\pizza_steak_sushi\\train\n",
        "Name: pizza, Path: data\\pizza_steak_sushi\\train\\pizza, Is File: False, Is Dir: True\n",
        "Name: steak, Path: data\\pizza_steak_sushi\\train\\steak, Is File: False, Is Dir: True\n",
        "Name: sushi, Path: data\\pizza_steak_sushi\\train\\sushi, Is File: False, Is Dir: True\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "# Scans the directory specified by target_dir and returns an iterator of os.DirEntry objects.\n",
        "entries = os.scandir(target_dir)\n",
        "# Converts the iterator into a list of os.DirEntry objects.\n",
        "entry_names = [entry.name for entry in entries]\n",
        "# Sorts the list of names in alphabetical order.\n",
        "sorted_entry_names = sorted(entry_names)\n",
        "# Stores the sorted list of entry names.\n",
        "sorted_entry_names\n",
        "```\n",
        "\n",
        "```\n",
        "['pizza', 'steak', 'sushi']\n",
        "```\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdBrm0vTxSmo"
      },
      "outputs": [],
      "source": [
        "target_dir = train_dir\n",
        "print(f\"Target directory: {target_dir}\")\n",
        "\n",
        "print(list(os.scandir(target_dir)))\n",
        "\n",
        "class_name = sorted([entry.name for entry in list(os.scandir(target_dir))])\n",
        "class_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VB4QhgtxSmo"
      },
      "source": [
        "```python\n",
        "import os\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "    # 1. Get the class names by scanning the target directory\n",
        "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
        "    # 2. Raise an error if class names could not be found\n",
        "    if not classes:\n",
        "        raise FileNotFoundError(f\"classes not found in {directory}\")\n",
        "    # 3. Create a dict of index labels(as computer prefer number over str labels)\n",
        "    class_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
        "    \n",
        "    return classes, class_to_idx\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        classes, class_indices = find_classes(train_dir)\n",
        "        print(\"Classes:\", classes)\n",
        "        print(\"Class Indices:\", class_indices)\n",
        "    except FileNotFoundError as e:\n",
        "        print(e)\n",
        "```\n",
        "\n",
        "```\n",
        "find_classes(train_dir)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HW9PRCGxSmp"
      },
      "source": [
        "#### **8.2 Create a coustom `Dataset` to replicate `ImageFolder`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMlERJZoxSmp"
      },
      "source": [
        "**To create our own custom dataset:**\n",
        "\n",
        "1. Subclass `torch.utils.data.Dataset`\n",
        "\n",
        "2. Create  standalone function `find_classes` that can be used by calling `ImageFolderCustom.find_classes(directory)` without creating an instance.\n",
        "\n",
        "3. `_init_` our subclass with a `target_dir` & then `transform` if we'd like to transform out data.\n",
        "\n",
        "\n",
        "4. Create several attributes:\n",
        "   1. `paths`: path to our image\n",
        "   2. `transform`: The transform we'd like to use.\n",
        "   3. `classes`: a `list` of target classes.\n",
        "   4. `class_to_idx`: a `dict` of the target classes mapped to integer labels\n",
        "\n",
        "5. Create a function to `load_images()`, this functon will open an image.\n",
        "\n",
        "6. Overwrite the `__len()__` method to return the length of our dataset.\n",
        "\n",
        "7. Overwrite the `__getitem()__` method to return the given sample when passed as index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVnGfYUpxSmq"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Tuple\n",
        "from pathlib import Path\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "\n",
        "#  1. Subclass torch.utils.data.Dataset-----------------------------------------\n",
        "class ImageFolderCustom(Dataset):\n",
        "    # These static methods don't need an instance of the class (self).\n",
        "    # They can be called directly on the class itself.\n",
        "    @staticmethod\n",
        "    def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "        \"\"\"\n",
        "        Finds classes in a directory and creates a mapping of class names to integer labels.\n",
        "        Args:\n",
        "            directory (str): Path to the directory containing class subdirectories.\n",
        "        Returns:\n",
        "            Tuple[List[str], Dict[str, int]]: Tuple containing a list of classes and a mapping of class names to integer labels.\n",
        "        \"\"\"\n",
        "        classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
        "        if not classes:\n",
        "            raise FileNotFoundError(f\"Class not found {directory}\")\n",
        "        class_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
        "        return classes, class_to_idx\n",
        "\n",
        "    # 2. Initialize our custom dataset------------------------------------------\n",
        "    def __init__(self,\n",
        "                 target_dir: str,\n",
        "                 transform: transforms.Compose=None):\n",
        "        \"\"\"\n",
        "        Custom dataset class for loading images from a directory.\n",
        "        Args:\n",
        "            target_dir (str): Path to the directory containing image files.\n",
        "            transform (transforms.Compose, optional): A torchvision transform to apply to the image data.\n",
        "        \"\"\"\n",
        "        self.paths = list(Path(target_dir).glob(\"*/*.jpg\"))  # Get all of the image paths\n",
        "        self.transform = transform\n",
        "        self.classes, self.class_to_idx = self.find_classes(target_dir)\n",
        "\n",
        "    # 4. Create a function to load images-----------------------------------\n",
        "    def load_image(self, index: int) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Opens an image from a given index and returns it.\n",
        "        Args:\n",
        "            index (int): Index of the image in the dataset.\n",
        "        Returns:\n",
        "            Image.Image: The loaded image.\n",
        "        \"\"\"\n",
        "        image_path = self.paths[index]\n",
        "        return Image.open(image_path)\n",
        "\n",
        "\n",
        "    # 5. Overwrite __len__()\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns the total number of samples in the dataset.\n",
        "        Returns:\n",
        "            int: Length of the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.paths)\n",
        "\n",
        "    # 6. Overwrite __getitem__() method to return a particular sample\n",
        "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
        "        \"\"\"\n",
        "        Returns one sample of data given an index.\n",
        "        Args:\n",
        "            index (int): Index of the sample to retrieve.\n",
        "        Returns:\n",
        "            tuple: Tuple containing the transformed image and its label.\n",
        "        \"\"\"\n",
        "        img = self.load_image(index)\n",
        "        class_name = self.paths[index].parent.name  # format: data_folder/class_name/image.jpg\n",
        "        class_idx = self.class_to_idx[class_name]\n",
        "\n",
        "        # Transform if necessary\n",
        "        if self.transform:\n",
        "            return self.transform(img), class_idx # return data, label (X, y)\n",
        "        else:\n",
        "            return img, class_idx # return untransformed image and label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkIrbRELTOLx"
      },
      "outputs": [],
      "source": [
        "img, label = train_data[0]\n",
        "print(img, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRUDsYuFUndH"
      },
      "outputs": [],
      "source": [
        "# Create a transform\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([         # Write a transform for image\n",
        "    transforms.Resize(size=(64, 64)),          # Resize our images to 64x64\n",
        "    transforms.RandomHorizontalFlip(p=0.5),    # Flip the images randomly on the horizontal ~ prob 50% i.e img transfrom 50% of time\n",
        "    transforms.ToTensor()                      # Turn the image into a torch.Tensor\n",
        "])\n",
        "\n",
        "test_transfrom = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ps9E8DvuVdpo"
      },
      "outputs": [],
      "source": [
        "# Test out ImageFolderCoustom\n",
        "train_data_custom = ImageFolderCustom(target_dir=train_dir,\n",
        "                                      transform=train_transform)\n",
        "\n",
        "test_data_custom = ImageFolderCustom(target_dir=test_dir,\n",
        "                                     transform=test_transfrom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sb37bU-eXDn2"
      },
      "outputs": [],
      "source": [
        "train_data_custom, test_data_custom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-LoWq4GXZ12"
      },
      "outputs": [],
      "source": [
        "len(train_data), len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnNyrdpMXsYO"
      },
      "outputs": [],
      "source": [
        "train_data.classes, train_data.class_to_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxAuoHbWYwPe"
      },
      "outputs": [],
      "source": [
        "train_data_custom.find_classes(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiUpoiUEX1KX"
      },
      "outputs": [],
      "source": [
        "# Check for equality between original ImageFolder Dataset and ImageFolderCustom Dataset\n",
        "print(train_data_custom.classes==train_data.classes)\n",
        "print(test_data_custom.classes==test_data.classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ymnPAZXlXG1"
      },
      "source": [
        "#### **8.3 Create a function to display random images**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS0OFIsjmrWq"
      },
      "source": [
        "1. **Input Parameters**:\n",
        "\n",
        "    - The function should take in the following parameters:\n",
        "        - `dataset`: The input dataset (e.g., a NumPy array or a PyTorch dataset).\n",
        "        - `class_names`: A list of class names corresponding to the dataset.\n",
        "        - `num_images`: The number of images to visualize (default is 10).\n",
        "        - `random_seed`: A random seed for reproducibility (default is 42).\n",
        "\n",
        "2. **Random Sampling**:\n",
        "    - Generate a list of random sample indexes from the target dataset. You can use NumPy’s `np.random.choice()` function.\n",
        "\n",
        "3. **Matplotlib Setup**:\n",
        "    - Create a Matplotlib plot to display the images. Set the figure size appropriately (e.g., `fig, axes = plt.subplots(1, num_images, figsize=(16, 8))`).\n",
        "\n",
        "4. **Loop and Plot**:\n",
        "    - Loop through the random sample indexes and plot each image using Matplotlib.\n",
        "    - Make sure the dimensions of the images align with Matplotlib (HWC format).\n",
        "\n",
        "5. **Display**:\n",
        "    - Show the plot using `plt.show()`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxs3NrPWrGhH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "from typing import List\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Create a function to take in a dataset\n",
        "def display_random_images(dataset: torch.utils.data.Dataset,\n",
        "                         classes: List[str] = None,\n",
        "                         num_image: int = 10,          # Default number is 10\n",
        "                         display_shape: bool = True,\n",
        "                         seed: int = None):\n",
        "\n",
        "    # 2. Adjust display if num_image is too high\n",
        "    if num_image > 10:\n",
        "        num_image = 10        # Setting it to 10\n",
        "        display_shape = False # Removing shape display\n",
        "        print(\"For display purposes, num_image shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
        "\n",
        "    # 3. Set the seed for reproducibility\n",
        "    if seed:\n",
        "        random.seed(seed)\n",
        "\n",
        "    # 4. Get random sample indexes\n",
        "    random_sample_idx = random.sample(range(len(dataset)), k=num_image) # k ~ sample size\n",
        "    print(f\"Random sample indexes: {random_sample_idx}\")\n",
        "\n",
        "    # 5. Setup plot\n",
        "    plt.figure(figsize=(16, 8))\n",
        "\n",
        "    # 6. Loop through the random sample indexes and plot them with matplotlib\n",
        "    for i, sample_idx in enumerate(random_sample_idx):\n",
        "        img, label = dataset[sample_idx][0], dataset[sample_idx][1] # Fix to correctly get image and label\n",
        "        img_adjust = img.permute(1, 2, 0) # [color_channels, height, width] -> [height, width, color_channels]\n",
        "\n",
        "        # Plot adjusted sample\n",
        "        plt.subplot(1, num_image, i + 1)\n",
        "        plt.imshow(img_adjust)\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        if classes:\n",
        "            title = f\"Class: {classes[label]}\"\n",
        "            if display_shape:\n",
        "                title += f\"\\nshape: {img_adjust.shape}\"\n",
        "            plt.title(title)\n",
        "        else:\n",
        "            if display_shape:\n",
        "                plt.title(f\"Shape: {img_adjust.shape}\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQfRexrUgejr"
      },
      "outputs": [],
      "source": [
        "# Display random images from the ImageFolderCustom Dataset\n",
        "display_random_images(train_data_custom,\n",
        "                      num_image=5,\n",
        "                      classes=class_names,\n",
        "                      seed=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsNWAUAhieOD"
      },
      "source": [
        "#### **8.4 Turn custom loaded images into `DataLoader's`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSvkVOJhiaWI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 1\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "train_dataloader_custom = DataLoader(dataset=train_data_custom,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     num_workers=NUM_WORKERS,\n",
        "                                     shuffle=True)\n",
        "\n",
        "test_dataloader_custom = DataLoader(dataset=test_data_custom,\n",
        "                                     batch_size=BATCH_SIZE,\n",
        "                                     num_workers=NUM_WORKERS,\n",
        "                                     shuffle=False)\n",
        "\n",
        "train_dataloader_custom, test_dataloader_custom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VncFyDVCkeG_"
      },
      "outputs": [],
      "source": [
        "# # Get the image and label from custom dataloader\n",
        "# img_custom, label_custom = next(iter(train_dataloader_custom))\n",
        "\n",
        "# img_custom.shape, label_custom.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3ZhLOFRlMHR"
      },
      "source": [
        "### **9. Data augmentation(Other forms of transforms)**\n",
        "\n",
        "- The process of adding diversity artificially to our training dataset.\n",
        "- Results in more generalizable to unseen data.\n",
        "\n",
        "[`trivailaugment`](https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#trivialaugmentwide)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlHSqV5QlCAR"
      },
      "outputs": [],
      "source": [
        "# Let's look at trivailaugment\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "test_transfrom = transforms.Compose([\n",
        "    transforms.Resize(size=(224, 224)),\n",
        "    transforms.ToTensor()\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mj8Wck1JminI"
      },
      "outputs": [],
      "source": [
        "image_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjsmmN98rVbk"
      },
      "outputs": [],
      "source": [
        "# Get all image paths\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "image_path_list[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aubHg16rqOD"
      },
      "outputs": [],
      "source": [
        "# Plot random transformed images\n",
        "plot_transformed_images(\n",
        "    image_path=image_path_list,\n",
        "    transform=train_transform,\n",
        "    n=3,\n",
        "    seed=None\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjDrnDZ3sHDz"
      },
      "source": [
        "### **10. `TinyVGG` Without Data Augmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VyLx3JoxF27"
      },
      "source": [
        "#### 10.1 **`Model 0`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4QdZ_6xo5WX"
      },
      "source": [
        "⭐[CNN Explainer](https://poloclub.github.io/cnn-explainer/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8AeqVEeRo5WX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Simple transformation pipeline for image preprocessing------------------------\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),  # Resize images to 64x64 pixels\n",
        "    transforms.ToTensor()              # Convert images to PyTorch tensors\n",
        "])\n",
        "\n",
        "# Load and transform data-------------------------------------------------------\n",
        "train_data_simple = ImageFolder(\n",
        "    root=train_dir,                    # Directory containing training images\n",
        "    transform=simple_transform         # Apply the defined transformations\n",
        ")\n",
        "\n",
        "test_data_simple = ImageFolder(\n",
        "    transform=simple_transform,         # Apply the same transformations as for training data\n",
        "    root=test_dir,                     # Directory containing test images\n",
        ")\n",
        "\n",
        "# Define batch size and number of workers for data loading----------------------\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "# Create DataLoader for training data\n",
        "train_dataloader_simple = DataLoader(\n",
        "    dataset=train_data_simple,  # Dataset to load from\n",
        "    batch_size=BATCH_SIZE,      # Number of samples per batch\n",
        "    num_workers=NUM_WORKERS,    # Number of subprocesses to use for data loading\n",
        "    shuffle=True                # Shuffle the data at every epoch\n",
        ")\n",
        "\n",
        "# Create DataLoader for test data\n",
        "test_dataloader_simple = DataLoader(\n",
        "    dataset=test_data_simple,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# Define the TinyVGG model class------------------------------------------------\n",
        "class TinyVGG(nn.Module):\n",
        "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "        super().__init__()  # Invoke the constructor of the parent class (nn.Module)\n",
        "\n",
        "        # Define the first convolutional block\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Define the second convolutional block\n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        # Define the classifier block\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),  # Flatten the input tensor\n",
        "            nn.Linear(in_features=hidden_units*13*13, out_features=output_shape),  # Fully connected layer\n",
        "        )\n",
        "\n",
        "    # Define the forward pass\n",
        "    def forward(self, x):\n",
        "        x = self.conv_block_1(x)  # Pass input through the first convolutional block\n",
        "        x = self.conv_block_2(x)  # Pass input through the second convolutional block\n",
        "        x = self.classifier(x)    # Pass input through the classifier\n",
        "        return x\n",
        "        # return self.classifier(self.conv_block_2(self.conv_block_1(x))) # benefits from operator fusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joXS_kBVUHsu"
      },
      "outputs": [],
      "source": [
        "# Modeling the instance of clas-------------------------------------------------\n",
        "torch.manual_seed(42)\n",
        "model_0 = TinyVGG(input_shape=3, # number of color channels in our image data\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(class_names)).to(device)\n",
        "\n",
        "model_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTl_C8hDo5Wa"
      },
      "outputs": [],
      "source": [
        "# Get a single image batch\n",
        "img, label = next(iter(train_dataloader_simple))\n",
        "img.shape, label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnfY4ixQo5Wb"
      },
      "outputs": [],
      "source": [
        "# try forward pass\n",
        "model_0(img.to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIhC40xdo5Wc"
      },
      "source": [
        "**`torchinfo`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K98EP-2GrUIP"
      },
      "outputs": [],
      "source": [
        "!pip -q install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtDoJznco5Wc"
      },
      "outputs": [],
      "source": [
        "import torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "summary(model_0, input_size=(1, 3, 64, 64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xvqre8To5Wd"
      },
      "source": [
        "#### **10.2 Create train and test loops functions**\n",
        "\n",
        "- `train_step()` - Takes the model and dataloader and train the model on the dataloader.\n",
        "- `test_step()` - Takes the model and dataloader and test the model on the dataloader.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZAKtAHno5Wd"
      },
      "source": [
        "```python\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
        "\n",
        "# Create accuracy function------------------------------------------------------\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n",
        "\n",
        "# Create the train_step()-------------------------------------------------------\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               accuracy_fn: accuracy_fn,\n",
        "               device: torch.device = device)\n",
        "\n",
        "    # Put the model in the training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Setup train loss and train accuracy values\n",
        "    train_loss, train_acc = 0, 0\n",
        "    \n",
        "    # loop through the dataloader data batches\n",
        "    for batch, (X, y) in  enumerate(dataloader):\n",
        "        # Send the data to the target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        \n",
        "        # 1. Forward pass(output the raw logits from the model)\n",
        "        y_pred = model(X)\n",
        "        \n",
        "        # 2. Calculating the loss and accuracy(per batch)\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "        train_acc += accuracy_fn(y_true=y, y_pred=torch.argmax(y_pred, dim=1))\n",
        "        \n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # 4. loss backward\n",
        "        loss.backward()\n",
        "        \n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "    # Adjust metric to get average loss and accuracy per batch\n",
        "    # Divide total train loss and accuracy by length of dataloader\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "# Create the test_step()--------------------------------------------------------\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              accuracy_fn: accuracy_fn,\n",
        "              device: torch.device = device):\n",
        "    \n",
        "    # Put the model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # setup test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on the inference mode\n",
        "    with torch.inference_mode():\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send the data to devide\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass(output the raw logits)\n",
        "            test_pred = model(X)\n",
        "\n",
        "            # 2. Calculate the loss and accuracy\n",
        "            loss = loss_fn(test_pred, y)\n",
        "            test_loss += loss.item\n",
        "            test_acc += accuracy_fn(y_true=y, y_pred=torch.argmax(test_pred, dim=1))\n",
        "\n",
        "        # Adjust metrics to get average loss and accuracy per batch\n",
        "        test_loss = test_loss / len(dataloader)\n",
        "        test_acc = test_acc / len(dataloader)\n",
        "        return test_loss, test_acc\n",
        "```   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4aamZArxqpU"
      },
      "outputs": [],
      "source": [
        "# Create train_step()----------------------------------------------------------\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer:torch.optim.Optimizer,\n",
        "               device=device):\n",
        "    # Put the model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # Setup train loss and train accuracy values\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Loop through data loader data batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Send data to the target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)  # output model logits\n",
        "\n",
        "        # 2. Calculate the loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Apply softmax to get probabilities for each class, then get the class index with the highest probability\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "\n",
        "        # Calculate accuracy by comparing predicted class indices with true labels\n",
        "        # (y_pred_class == y) returns a tensor of boolean values where the predictions are correct\n",
        "        # .sum().item() counts the number of correct predictions\n",
        "        # / len(y_pred) normalizes by the number of predictions to get accuracy\n",
        "        train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "# Create a test step()----------------------------------------------------------\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device=device):\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Setup test loss and test accuracy values\n",
        "    test_loss, test_acc = 0,  0\n",
        "\n",
        "    # Turn on inference mode\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to the target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate the loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Get the predicted class indices by finding the index with the highest logit (score) for each input\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "\n",
        "            # Calculate accuracy by comparing predicted class indices with true labels\n",
        "            # (test_pred_labels == y) returns a tensor of boolean values where the predictions are correct\n",
        "            # .sum().item() counts the number of correct predictions\n",
        "            # / len(test_pred_labels) normalizes by the number of predictions to get accuracy\n",
        "            test_acc += (test_pred_labels == y).sum().item() / len(test_pred_labels)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Y3R7dbQ1R5S"
      },
      "source": [
        "#### **10.3 Creating a `train()` function to combine `train_step()` and `test_step()`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDOp53bJEqlc"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Create a train function that take in various model parameter + optimizer + dataloader + loss funciton\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader,\n",
        "          test_dataloader,\n",
        "          optimizer,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5,\n",
        "          device=device):\n",
        "\n",
        "    # 2. Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []}\n",
        "\n",
        "    # 3. Loop through training and testing steps for number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           dataloader=train_dataloader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           optimizer=optimizer,\n",
        "                                           device=device)\n",
        "\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "                                         dataloader=test_dataloader,\n",
        "                                         loss_fn=loss_fn,\n",
        "                                         device=device)\n",
        "\n",
        "        # 4. Print out what's happening\n",
        "        if epoch%10 == 0:\n",
        "            print(f\"Epoch: {epoch} | Train loss: {train_loss:.4f} | Train acc: {train_acc:.4f} | Test loss: {test_loss:.4f} | Test acc: {test_acc:.4f}\")\n",
        "\n",
        "        # 5. Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    # 6. Return the filled results at the end of the epochs\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2dUcLS5J2I_"
      },
      "source": [
        "#### **10.4 Train and evaluate `model_0`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aRK2pwVE77Y"
      },
      "outputs": [],
      "source": [
        "# set the random seed\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# set number of epochs\n",
        "EPOCHS = 80\n",
        "\n",
        "# Recreate the instance of TinyVGG\n",
        "model_0 = TinyVGG(input_shape=3,  # Number of color channels of out target image\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(class_names)).to(device)\n",
        "\n",
        "# Setup loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_0.parameters(),\n",
        "                             lr=0.001)\n",
        "\n",
        "\n",
        "# start the Timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model_0\n",
        "model_0_results = train(model=model_0,\n",
        "                        train_dataloader=train_dataloader_simple,\n",
        "                        test_dataloader=test_dataloader_simple,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=EPOCHS)\n",
        "\n",
        "# End the Timer\n",
        "end_timer = timer()\n",
        "print(f\"Total train time: {(end_timer - start_time):.3f} sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfKtAG2PSvSm"
      },
      "source": [
        "- Train Time CPU(`epoch=100`) $\\rightarrow$  `198.310` sec\n",
        "- Train Time GPU(`epoch=100`) $\\rightarrow$  `112.959` sec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ONwNefPA5E-"
      },
      "source": [
        "#### **10.5 Plot the loss curves of `Model_0`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f94bVbUeA_P8"
      },
      "outputs": [],
      "source": [
        "model_0_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8Z4uk52IYB1"
      },
      "outputs": [],
      "source": [
        "num_epoch = len(model_0_results[\"train_loss\"])\n",
        "num_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrICkAMfBC-F"
      },
      "outputs": [],
      "source": [
        "model_0_results.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw-AcOgcEg3c"
      },
      "outputs": [],
      "source": [
        "def loss_plot_curves(results: Dict[str, List[float]]):\n",
        "    # Get the loss and accuracy values of the results dictionary\n",
        "    train_loss = results[\"train_loss\"]\n",
        "    test_loss = results[\"test_loss\"]\n",
        "    train_acc = results[\"train_acc\"]\n",
        "    test_acc = results[\"test_acc\"]\n",
        "\n",
        "    # Epochs\n",
        "    epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "    # Plots\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 1) # Row->1, Col->2, idx->1\n",
        "    plt.plot(epochs, train_loss, label=\"train_loss\")\n",
        "    plt.plot(epochs, test_loss, label=\"test_loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 2) # Row->1, Col->2, idx->2\n",
        "    plt.plot(epochs, train_acc, label=\"train_acc\")\n",
        "    plt.plot(epochs, test_acc, label=\"test_acc\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuJgqdkRW9be"
      },
      "outputs": [],
      "source": [
        "loss_plot_curves(model_0_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI6h53xrRJZC"
      },
      "source": [
        "### **11. `TinyVGG` With Data Augmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnHO69t3RJZC"
      },
      "source": [
        "#### **11.1 `Model_1`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEcpbKZyRJZD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "# set the random seed\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Data Transform with TriviailAugment-------------------------------------------\n",
        "train_transform_trivial = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "test_transform_simple = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# ImageFolder -> dataset--------------------------------------------------------\n",
        "train_data_argumented = datasets.ImageFolder(root=train_dir,\n",
        "                                             transform=train_transform_trivial)\n",
        "\n",
        "test_data_simple = datasets.ImageFolder(root=test_dir,\n",
        "                                             transform=test_transform_simple)\n",
        "\n",
        "\n",
        "# Dataset -> DataLoader---------------------------------------------------------\n",
        "BATCH_SIZE =32\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "train_dataloader_augmented = DataLoader(dataset=train_data_argumented,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        num_workers=NUM_WORKERS,\n",
        "                                        shuffle=True)\n",
        "\n",
        "test_dataloader_simple = DataLoader(dataset=test_data_simple,\n",
        "                                        batch_size=BATCH_SIZE,\n",
        "                                        num_workers=NUM_WORKERS,\n",
        "                                        shuffle=False)\n",
        "\n",
        "\n",
        "# Create Model_1 and sent it to Target Device\n",
        "model_1 = TinyVGG(input_shape=3, # number of color channels in our image data\n",
        "                  hidden_units=10,\n",
        "                  output_shape=len(class_names)).to(device)\n",
        "\n",
        "print(model_0)\n",
        "print(\"-\"*70)\n",
        "\n",
        "# Setup Loss and Optimizer------------------------------------------------------\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.001)\n",
        "\n",
        "# Train and evaluate------------------------------------------------------------\n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "start_time = timer()\n",
        "\n",
        "model_1_results = train(model=model_1,\n",
        "                        train_dataloader=train_dataloader_augmented,\n",
        "                        test_dataloader=test_dataloader_simple,\n",
        "                        optimizer=optimizer,\n",
        "                        loss_fn=loss_fn,\n",
        "                        epochs=NUM_EPOCHS,\n",
        "                        device=device)\n",
        "end_time = timer()\n",
        "\n",
        "print(f\"Total training time for model_1: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5HOsRuARJZD"
      },
      "source": [
        "#### **11.2 Plot the loss curves of `model_1`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oHITqJJRJZD"
      },
      "outputs": [],
      "source": [
        "loss_plot_curves(model_1_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bnUNzb7RJZD"
      },
      "source": [
        "####  **11.3 Compare model results**\n",
        "\n",
        "After evaluating our modelling experiments on their own, it's important to compare them to each other.\n",
        "\n",
        "There's a few different ways to do this:\n",
        "\n",
        "1. **Hard coding** (what we're doing)\n",
        "2. [**PyTorch + Tensorboard**](https://pytorch.org/docs/stable/tensorboard.html)\n",
        "3. [**Weights & Biases**](https://wandb.ai/site/experiment-tracking](https://wandb.ai/site/experiment-tracking)\n",
        "4. [**MLFlow**](https://mlflow.org/)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "model_0_df = pd.DataFrame(model_0_results)\n",
        "model_1_df = pd.DataFrame(model_1_results)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# get the number of epochs\n",
        "epochs = range(len(model_0_df))\n",
        "\n",
        "# Train loss\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs, model_0_df[\"train_loss\"], label=\"Model_0\")\n",
        "plt.plot(epochs, model_1_df[\"train_loss\"], label=\"Model_1\")\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Test loss\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs, model_0_df[\"test_loss\"], label=\"Model_0\")\n",
        "plt.plot(epochs, model_1_df[\"test_loss\"], label=\"Model_1\")\n",
        "plt.title(\"Test Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Train Accuracy\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(epochs, model_0_df[\"train_acc\"], label=\"Model_0\")\n",
        "plt.plot(epochs, model_1_df[\"train_acc\"], label=\"Model_1\")\n",
        "plt.title(\"Train Acc\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Test Accuracy\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(epochs, model_0_df[\"test_acc\"], label=\"Model_0\")\n",
        "plt.plot(epochs, model_1_df[\"test_acc\"], label=\"Model_1\")\n",
        "plt.title(\"Test Acc\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "9PJwX3-7TYRz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}